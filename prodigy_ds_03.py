# -*- coding: utf-8 -*-
"""Prodigy_DS_03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kWznxGZJnNAsPzMginSnV5FpIPKSt3NZ
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay

bank = pd.read_csv(r"/content/drive/MyDrive/Colab Notebooks/Data/Internship/bank.csv",sep=';')
bank.head(10)

bank.shape

bank.columns

bank.info()

bank.duplicated().sum()

bank.info

bank.describe()

bank.isnull().sum()

bank[bank.duplicated()]

sns.histplot(x="age", data=bank, kde=True, hue="y", palette="dark")
plt.title("Distribution of Ages and Deposit Status\n")
plt.show()

#Visualizing Occupation Distribution
plt.figure(figsize=(15,4))
sns.countplot(x="job", data=bank, hue="y", palette="bright")
plt.title("Distribution of Occupations and Deposits\n")
plt.show()

plt.figure(figsize=(10, 5))
sns.countplot(x="marital", data=bank, hue="y",palette="bright")
plt.title("Marital Status and Deposits\n")
plt.show()

# Visualizing Education Status Distribution
plt.figure(figsize=(12, 4))
sns.countplot(x="education", data=bank, hue="y",palette="bright")
plt.title("Distribution of Education Status and Deposits\n")
plt.show()

bank.columns

bank.head()

bank['default'].value_counts()

plt.figure(figsize=(6, 3.5))  # Adjusted figure size
sns.countplot(x="housing", data=bank, hue="y", palette="colorblind")
plt.title("Distribution of Housing Loans and Deposits\n")
plt.show()

plt.figure(figsize=(6, 3.5))
sns.countplot(x="loan", data=bank, hue="y", palette="muted")
plt.title("Distribution of Personal Loans and Deposits\n")
plt.show()

# Getting value counts for the 'y' column in the bank dataframe
keys = bank.y.value_counts().index
data = bank.y.value_counts().values

#figure size
plt.figure(figsize=(6, 3.5))

#explode parameter for pie chart
explode = [0, 0.1]

plt.pie(data, labels=keys, explode=explode, autopct='%.0f%%', colors=['skyblue', 'lightgreen'])

plt.show()

cols = bank.select_dtypes("object").columns
cols

le = LabelEncoder()

# Applying LabelEncoder to each column
bank[cols] = bank[cols].apply(le.fit_transform)

bank.head()

plt.figure(figsize=(23,10))
sns.heatmap(bank.corr(), cmap='RdBu_r', annot=True)
plt.show()

#Splitting input and output
X = bank.drop("y", axis=1)
y = bank["y"]

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Splitting the data into training and testing sets
train_X, test_X, train_y, test_y = train_test_split(X_scaled, y, test_size=0.3)

decision_tree = DecisionTreeClassifier()

# Train the classifier on the training data
decision_tree.fit(train_X, train_y)

print('Train Score: {}'.format(decision_tree.score(train_X, train_y)))
print('Test Score: {}'.format(decision_tree.score(test_X, test_y)))

# Cross-validating scores
cross_val_mean = cross_val_score(decision_tree, train_X, train_y, cv=5).mean()
cross_val_mean

# Making predictions on the test data
ypred = decision_tree.predict(test_X)

# Classification report
print(classification_report(test_y, ypred))

param_grid = {
    'max_depth': [3, 5, 7, 10, None],
    'criterion': ['gini', 'entropy'],
    'min_samples_leaf': [3, 5, 7, 9, 10, 20]
}


grid_search = GridSearchCV(decision_tree, param_grid, cv=5)

# Fitting grid_search to training data
grid_search.fit(train_X, train_y)

best_estimator = grid_search.best_estimator_

print("Best Parameters:", grid_search.best_params_)

gscv = GridSearchCV(decision_tree, param_grid, cv=5, verbose=1)

# Fitting GridSearchCV to training data
gscv.fit(train_X, train_y)

best_params = gscv.best_params_
best_params

best_estimator = gscv.best_estimator_
best_estimator

# Calculating cross-validated scores using best estimator
cross_val_mean = cross_val_score(gscv.best_estimator_, train_X, train_y, cv=5).mean()
cross_val_mean

# DecisionTreeClassifier with specified hyperparameters
clf = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf=3)
clf.fit(train_X, train_y)

print('Train Score: {}'.format(clf.score(train_X, train_y)))
print('Test Score: {}'.format(clf.score(test_X, test_y)))

pred_y = clf.predict(test_X)
pred_y

# Generate confusion matrix
cm = confusion_matrix(pred_y, test_y)

# Confusion matrix
disp = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)
disp.plot(cmap='plasma', colorbar=True)
plt.show()

report = classification_report(pred_y, test_y)
print(report)

#Accuracy Score
accuracy = accuracy_score(test_y,pred_y)
print("Test Accuracy of Decision Tree Classifier : {}".format(accuracy*100))

#Cross Validation Score
Cross_val = cross_val_score(clf, test_X,test_y, cv=5).mean()
print("Cross-Validation Accuracy Scores Decision Tree : ",Cross_val*100)

from sklearn import tree
plt.figure(figsize=(25, 20))
tree.plot_tree(clf, filled=True, feature_names=X.columns)
plt.show()

